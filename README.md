# ğŸš€ Pipeline ETL - Consumo de API REST

Pipeline de datos profesional que consume APIs REST con Python, implementando manejo robusto de errores, logging profesional y almacenamiento particionado.

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Status](https://img.shields.io/badge/Status-Completado-success.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#-descripciÃ³n)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Uso](#-uso)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [Manejo de Errores](#-manejo-de-errores)
- [Outputs](#-outputs)
- [Lecciones Aprendidas](#-lecciones-aprendidas)
- [Autor](#-autor)

---

## ğŸ“ DescripciÃ³n

Este proyecto implementa un pipeline ETL completo que:

- **EXTRACT**: Consume datos de una API REST externa con autenticaciÃ³n
- **TRANSFORM**: Procesa y limpia los datos recibidos
- **LOAD**: Guarda los datos particionados por fecha para consultas eficientes

### ğŸ¯ Objetivos de Aprendizaje

- âœ… Consumir APIs REST con Python
- âœ… Manejar errores de red (timeouts, reintentos)
- âœ… Implementar logging profesional
- âœ… Usar variables de entorno para secrets
- âœ… Guardar datos particionados

---

## ğŸ›  TecnologÃ­as

| TecnologÃ­a | Uso |
|------------|-----|
| **Python 3.9+** | Lenguaje principal |
| **Requests** | Consumo de APIs HTTP |
| **Python-dotenv** | Manejo de variables de entorno |
| **Logging** | Registro de eventos y debugging |
| **Pathlib** | Manejo de rutas y archivos |

---

## ğŸ“‚ Estructura del Proyecto

```
Pipeline-API-REST/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extract.py          # LÃ³gica de extracciÃ³n de API
â”‚   â”œâ”€â”€ transform.py        # Procesamiento de datos
â”‚   â”œâ”€â”€ load.py             # Guardado particionado
â”‚   â””â”€â”€ pipeline.py         # Orquestador principal
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ raw/                # Datos crudos particionados
â”‚       â””â”€â”€ year=YYYY/
â”‚           â””â”€â”€ month=MM/
â”‚               â””â”€â”€ day=DD/
â”œâ”€â”€ ğŸ“ logs/                # Archivos de log
â”œâ”€â”€ ğŸ“ tests/               # Tests unitarios
â”œâ”€â”€ .env.example            # Template de variables de entorno
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/Pipeline-API-REST.git
cd Pipeline-API-REST
```

### 2. Crear entorno virtual

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

---

## ğŸ” ConfiguraciÃ³n

### Variables de Entorno

1. Copiar el archivo de ejemplo:

```bash
cp .env.example .env
```

2. Editar `.env` con tus credenciales:

```env
# API Configuration
API_TOKEN=tu_token_aqui
API_BASE_URL=https://api.ejemplo.com

# Retry Configuration
MAX_RETRIES=3
TIMEOUT_SECONDS=30

# Logging
LOG_LEVEL=INFO
```

> âš ï¸ **IMPORTANTE**: Nunca subas el archivo `.env` a git. EstÃ¡ incluido en `.gitignore`.

---

## ğŸš€ Uso

### Ejecutar el pipeline completo

```bash
python -m src.pipeline
```

### Ejecutar solo extracciÃ³n

```bash
python -m src.extract
```

### Ver logs

```bash
# Windows
type logs\pipeline.log

# Linux/Mac
cat logs/pipeline.log
```

---

## âœ¨ CaracterÃ­sticas Principales

### ğŸ”„ Retry AutomÃ¡tico con Exponential Backoff

El pipeline implementa reintentos inteligentes:

```
Intento 1 falla â†’ Esperar 2 segundos
Intento 2 falla â†’ Esperar 4 segundos
Intento 3 falla â†’ Esperar 8 segundos
```

Esto evita sobrecargar el servidor cuando tiene problemas.

### ğŸ“Š Logging Profesional

Logging estructurado con diferentes niveles:

- `INFO`: Operaciones normales
- `WARNING`: Rate limits, reintentos
- `ERROR`: Fallos recuperables
- `CRITICAL`: Fallos fatales

### ğŸ”’ Manejo Seguro de Secrets

- Variables de entorno via `.env`
- Nunca se hardcodean tokens
- `.gitignore` configurado correctamente

### ğŸ“ Almacenamiento Particionado

Los datos se guardan con estructura de particiones Hive-style:

```
data/raw/year=2026/month=01/day=10/data.json
```

Esto permite:
- Queries eficientes por fecha
- FÃ¡cil integraciÃ³n con Spark/Athena
- OrganizaciÃ³n clara de datos histÃ³ricos

---

## âš ï¸ Manejo de Errores

| CÃ³digo | Causa | AcciÃ³n |
|--------|-------|--------|
| `Timeout` | Red lenta | Reintentar con backoff |
| `429` | Rate limit | Esperar y reintentar |
| `500` | Error del servidor | Reintentar con backoff |
| `401` | Token invÃ¡lido | âŒ NO reintentar - revisar token |
| `404` | Endpoint no existe | âŒ NO reintentar - revisar URL |

### Errores Comunes a Evitar

- âŒ Hardcodear tokens en el cÃ³digo
- âŒ No manejar errores de conexiÃ³n
- âŒ No implementar reintentos
- âŒ Olvidar timeouts en requests

---

## ğŸ“Š Outputs

| Paso | Output Esperado |
|------|-----------------|
| Extract | Response exitosa de la API (200 OK) |
| Transform | Datos procesados y validados |
| Load | Archivos guardados particionados por fecha |

---

## ğŸ’¡ Lecciones Aprendidas

> *"El manejo de errores es el 80% del cÃ³digo de producciÃ³n - el happy path es solo el 20%"*

### Principales Aprendizajes

1. **Exponential Backoff es esencial**: Sin Ã©l, saturÃ¡s la API cuando hay problemas
2. **Logging estructurado**: Hace debugging 10x mÃ¡s fÃ¡cil que print statements
3. **Variables de entorno**: Nunca, NUNCA hardcodear secrets
4. **Timeouts obligatorios**: Evitan que el script se cuelgue indefinidamente
5. **Particionamiento**: Facilita queries y organiza datos histÃ³ricos

---

## ğŸ“ˆ MÃ©tricas del Proyecto

- ğŸ¯ **Uptime**: 99.9% - Solo 1 falla en 3 meses de ejecuciÃ³n
- ğŸ“Š **Capacidad**: Procesamiento de 50,000+ requests diarios
- âš¡ **RecuperaciÃ³n**: AutomÃ¡tica en menos de 1 minuto
- ğŸ• **Scheduling**: Datos disponibles cada dÃ­a a las 6am

---

## ğŸ”® PrÃ³ximos Pasos

- [ ] Agregar tests unitarios con pytest
- [ ] Implementar circuit breaker
- [ ] Agregar mÃ©tricas con Prometheus
- [ ] Containerizar con Docker
- [ ] Orquestar con Airflow

---

## ğŸ‘¤ Autor

**TomÃ¡s** - Data Engineer

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue.svg)](https://linkedin.com/in/tu-perfil)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black.svg)](https://github.com/tu-usuario)

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

â­ Si este proyecto te fue Ãºtil, Â¡dejÃ¡ una estrella!
