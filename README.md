# ğŸš€ Pipeline ETL - Consumo de API REST

Pipeline de datos profesional que consume una API REST de e-commerce con Python, implementando manejo robusto de errores, logging profesional y almacenamiento en formato Parquet con particionamiento por fecha.

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Status](https://img.shields.io/badge/Status-Completado-success.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#-descripciÃ³n)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Uso](#-uso)
- [Tablas Procesadas](#-tablas-procesadas)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [Manejo de Errores](#-manejo-de-errores)
- [Outputs](#-outputs)
- [Lecciones Aprendidas](#-lecciones-aprendidas)
- [Autor](#-autor)

---

## ğŸ“ DescripciÃ³n

Este proyecto implementa un pipeline ETL completo que:

- **EXTRACT**: Consume datos de una API REST de e-commerce con autenticaciÃ³n y reintentos automÃ¡ticos
- **TRANSFORM**: Procesa y limpia 11 tablas diferentes, optimizando tipos de datos y manejando valores nulos
- **LOAD**: Guarda los datos en formato Parquet, con Ã³rdenes particionadas por aÃ±o/mes

### ğŸ¯ Objetivos de Aprendizaje

- âœ… Consumir APIs REST con Python
- âœ… Manejar errores de red (timeouts, reintentos con exponential backoff)
- âœ… Implementar logging profesional
- âœ… Usar variables de entorno para secrets
- âœ… Guardar datos en formato Parquet particionado

---

## ğŸ›  TecnologÃ­as

| TecnologÃ­a | Uso |
|------------|-----|
| **Python 3.9+** | Lenguaje principal |
| **Requests** | Consumo de APIs HTTP |
| **Pandas** | Procesamiento y transformaciÃ³n de datos |
| **PyArrow** | Escritura de archivos Parquet |
| **Python-dotenv** | Manejo de variables de entorno |
| **Logging** | Registro de eventos y debugging |

---

## ğŸ“‚ Estructura del Proyecto

```
Pipeline-API-REST/
â”œâ”€â”€ config.py               # ConfiguraciÃ³n y variables de entorno
â”œâ”€â”€ ingest.py               # ExtracciÃ³n de datos con retry
â”œâ”€â”€ transform.py            # Transformaciones para cada tabla
â”œâ”€â”€ etl-API.py              # Orquestador principal del pipeline
â”œâ”€â”€ exploracion.ipynb       # Notebook de exploraciÃ³n de datos
â”œâ”€â”€ output/                 # Datos procesados
â”‚   â”œâ”€â”€ categories.parquet
â”‚   â”œâ”€â”€ brands.parquet
â”‚   â”œâ”€â”€ suppliers.parquet
â”‚   â”œâ”€â”€ warehouses.parquet
â”‚   â”œâ”€â”€ products.parquet
â”‚   â”œâ”€â”€ inventory.parquet
â”‚   â”œâ”€â”€ customers.parquet
â”‚   â”œâ”€â”€ promotions.parquet
â”‚   â”œâ”€â”€ orders.parquet
â”‚   â”œâ”€â”€ order_items.parquet
â”‚   â”œâ”€â”€ reviews.parquet
â”‚   â””â”€â”€ orders/             # Ã“rdenes particionadas
â”‚       â””â”€â”€ {year}/{month}/
â”œâ”€â”€ .env                    # Variables de entorno (no versionado)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/Pipeline-API-REST.git
cd Pipeline-API-REST
```

### 2. Crear entorno virtual

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

---

## ğŸ” ConfiguraciÃ³n

### Variables de Entorno

Crear un archivo `.env` en la raÃ­z del proyecto:

```env
EMAIL=tu_email@ejemplo.com
API_TOKEN=tu_token_aqui
API_BASE_URL=https://iansaura.com/api
```

> âš ï¸ **IMPORTANTE**: Nunca subas el archivo `.env` a git. EstÃ¡ incluido en `.gitignore`.

---

## ğŸš€ Uso

### Ejecutar el pipeline completo

```bash
python etl-API.py
```

### Explorar los datos

Abrir `exploracion.ipynb` en Jupyter o VS Code para analizar la estructura de cada tabla.

---

## ğŸ“Š Tablas Procesadas

El pipeline procesa 11 tablas de un sistema de e-commerce:

| Tabla | DescripciÃ³n | Transformaciones Principales |
|-------|-------------|------------------------------|
| `categories` | CategorÃ­as de productos | Manejo de nulls, tipos category |
| `brands` | Marcas | OptimizaciÃ³n a category |
| `suppliers` | Proveedores | NormalizaciÃ³n de email, rating a float32 |
| `warehouses` | DepÃ³sitos | OptimizaciÃ³n de enteros a int32 |
| `products` | Productos | ConversiÃ³n de fechas, precios a float32 |
| `inventory` | Inventario | Fechas de restock, niveles de stock |
| `customers` | Clientes | 3 columnas de fecha, segmentos |
| `promotions` | Promociones | Fechas inicio/fin, tipos de descuento |
| `orders` | Ã“rdenes | Fecha, status, mÃ©todos de pago |
| `order_items` | Items de Ã³rdenes | IDs nullable, precios optimizados |
| `reviews` | ReseÃ±as | Rating a float16, fechas |

---

## âœ¨ CaracterÃ­sticas Principales

### ğŸ”„ Retry AutomÃ¡tico con Exponential Backoff

El pipeline implementa reintentos inteligentes en `ingest.py`:

```
Intento 1 falla â†’ Esperar 2 segundos
Intento 2 falla â†’ Esperar 4 segundos
Intento 3 falla â†’ Esperar 8 segundos
```

### ğŸ“Š Logging Profesional

Logging estructurado con diferentes niveles:

```
2026-01-10 20:43:32,037 - INFO - Fetching 1000 rows of ecommerce data...
2026-01-10 20:43:32,690 - INFO - Table: categories
2026-01-10 20:43:32,693 - INFO - Transforming data...
```

### ğŸ”’ Manejo Seguro de Secrets

- Variables de entorno via `.env` y `python-dotenv`
- ValidaciÃ³n de configuraciÃ³n en `config.py`
- `.gitignore` configurado correctamente

### ğŸ“ Almacenamiento en Parquet

- Formato columnar eficiente para analytics
- CompresiÃ³n automÃ¡tica
- Ã“rdenes particionadas por `year/month` para queries eficientes

---

## âš ï¸ Manejo de Errores

| CÃ³digo | Causa | AcciÃ³n |
|--------|-------|--------|
| `Timeout` | Red lenta | Reintentar con backoff |
| `429` | Rate limit | Esperar y reintentar |
| `500` | Error del servidor | Reintentar con backoff |
| `401` | Token invÃ¡lido | âŒ NO reintentar - revisar token |
| `404` | Endpoint no existe | âŒ NO reintentar - revisar URL |

### Errores Comunes a Evitar

- âŒ Hardcodear tokens en el cÃ³digo
- âŒ No manejar errores de conexiÃ³n
- âŒ No implementar reintentos
- âŒ Olvidar timeouts en requests

---

## ğŸ“Š Outputs

```
output/
â”œâ”€â”€ categories.parquet      (10 registros)
â”œâ”€â”€ brands.parquet
â”œâ”€â”€ suppliers.parquet       (8 registros)
â”œâ”€â”€ warehouses.parquet      (5 registros)
â”œâ”€â”€ products.parquet        (100 registros)
â”œâ”€â”€ inventory.parquet       (195 registros)
â”œâ”€â”€ customers.parquet       (334 registros)
â”œâ”€â”€ promotions.parquet      (10 registros)
â”œâ”€â”€ orders.parquet          (1000 registros)
â”œâ”€â”€ order_items.parquet     (3031 registros)
â”œâ”€â”€ reviews.parquet         (200 registros)
â””â”€â”€ orders/
    â”œâ”€â”€ 2023/
    â”œâ”€â”€ 2024/
    â”œâ”€â”€ 2025/
    â””â”€â”€ 2026/
```

---

## ğŸ’¡ Lecciones Aprendidas

> *"El manejo de errores es el 80% del cÃ³digo de producciÃ³n - el happy path es solo el 20%"*

### Principales Aprendizajes

1. **Exponential Backoff es esencial**: Sin Ã©l, saturÃ¡s la API cuando hay problemas
2. **Logging estructurado**: Hace debugging 10x mÃ¡s fÃ¡cil que print statements
3. **Variables de entorno**: Nunca, NUNCA hardcodear secrets
4. **Parquet > CSV**: Mejor compresiÃ³n, tipos de datos preservados, mÃ¡s rÃ¡pido
5. **Particionamiento**: Facilita queries y organiza datos histÃ³ricos

---

## ğŸ‘¤ Autor

**TomÃ¡s** - Data Engineer

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue.svg)](https://linkedin.com/in/tomasamundarain)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black.svg)](https://github.com/tomy07417)

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

â­ Si este proyecto te fue Ãºtil, Â¡dejÃ¡ una estrella!
